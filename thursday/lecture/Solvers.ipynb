{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solvers ‚öôÔ∏è"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise, you will investigate the effects of different `solvers` on `LogisticRegression` models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üëá Run the code below to import the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.47</td>\n",
       "      <td>5.97</td>\n",
       "      <td>7.36</td>\n",
       "      <td>10.17</td>\n",
       "      <td>6.84</td>\n",
       "      <td>9.15</td>\n",
       "      <td>9.78</td>\n",
       "      <td>9.52</td>\n",
       "      <td>10.34</td>\n",
       "      <td>8.80</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.05</td>\n",
       "      <td>8.84</td>\n",
       "      <td>9.76</td>\n",
       "      <td>8.38</td>\n",
       "      <td>10.15</td>\n",
       "      <td>6.91</td>\n",
       "      <td>9.70</td>\n",
       "      <td>9.01</td>\n",
       "      <td>9.23</td>\n",
       "      <td>8.80</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.59</td>\n",
       "      <td>10.71</td>\n",
       "      <td>10.84</td>\n",
       "      <td>10.97</td>\n",
       "      <td>9.03</td>\n",
       "      <td>10.42</td>\n",
       "      <td>11.46</td>\n",
       "      <td>11.25</td>\n",
       "      <td>11.34</td>\n",
       "      <td>9.06</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.00</td>\n",
       "      <td>8.44</td>\n",
       "      <td>8.32</td>\n",
       "      <td>9.65</td>\n",
       "      <td>7.87</td>\n",
       "      <td>10.92</td>\n",
       "      <td>6.97</td>\n",
       "      <td>11.07</td>\n",
       "      <td>10.66</td>\n",
       "      <td>8.89</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12.12</td>\n",
       "      <td>13.44</td>\n",
       "      <td>10.35</td>\n",
       "      <td>9.95</td>\n",
       "      <td>11.09</td>\n",
       "      <td>9.38</td>\n",
       "      <td>10.22</td>\n",
       "      <td>9.04</td>\n",
       "      <td>7.68</td>\n",
       "      <td>11.38</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0           9.47              5.97         7.36           10.17       6.84   \n",
       "1          10.05              8.84         9.76            8.38      10.15   \n",
       "2          10.59             10.71        10.84           10.97       9.03   \n",
       "3          11.00              8.44         8.32            9.65       7.87   \n",
       "4          12.12             13.44        10.35            9.95      11.09   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density  sulphates  alcohol  \\\n",
       "0                 9.15                  9.78     9.52      10.34     8.80   \n",
       "1                 6.91                  9.70     9.01       9.23     8.80   \n",
       "2                10.42                 11.46    11.25      11.34     9.06   \n",
       "3                10.92                  6.97    11.07      10.66     8.89   \n",
       "4                 9.38                 10.22     9.04       7.68    11.38   \n",
       "\n",
       "   quality rating  \n",
       "0               6  \n",
       "1               7  \n",
       "2               4  \n",
       "3               8  \n",
       "4               3  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"https://wagon-public-datasets.s3.amazonaws.com/05-Machine-Learning/04-Under-the-Hood/solvers_dataset.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The dataset consists of different wines üç∑\n",
    "- The features describe different properties of the wines \n",
    "- The target üéØ is a quality rating given by an expert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Target engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, you are going to transform the ratings into a binary target."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üëá How many observations are there for each rating?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 6,  7,  4,  8,  3,  1,  2, 10,  5,  9])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['quality rating'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "delete"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10    10143\n",
       "5     10124\n",
       "1     10090\n",
       "2     10030\n",
       "8      9977\n",
       "6      9961\n",
       "9      9955\n",
       "7      9954\n",
       "4      9928\n",
       "3      9838\n",
       "Name: quality rating, dtype: int64"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['quality rating'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì Create `y` by transforming the target into a binary classification task where quality ratings below 6 are bad [0], and ratings of 6 and above are good [1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "y = df['quality rating'].map(lambda x: 0 if x < 6 else 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì Check the class balance of the new binary target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    50010\n",
       "1    49990\n",
       "Name: quality rating, dtype: int64"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì Create your `X` by normalising the features. This will allow for fair comparison of different solvers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# Select only the features \n",
    "X = df.drop(columns=['quality rating'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Fit scaler to features\n",
    "scaler = MinMaxScaler().fit(X)\n",
    "\n",
    "# Scale features\n",
    "X_scaled = scaler.transform(X)\n",
    "\n",
    "# keep column names\n",
    "X_scaled = pd.DataFrame(X_scaled)\n",
    "X_scaled.columns = X.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. LogisticRegression solvers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì Logistic Regression models can be optimized using different **solvers**. Make a comparison of the available solvers':\n",
    "- Fit time - which solver is **the fastest**?\n",
    "- Precision - **how different** are their respective precision scores?\n",
    "\n",
    "Available solvers for Logistic Regression are `['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']`\n",
    " \n",
    "For more information on these 5 solvers, check out [this Stack Overflow thread](https://stackoverflow.com/questions/38640109/logistic-regression-python-solvers-defintions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision score</th>\n",
       "      <th>fit time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>newton-cg</th>\n",
       "      <td>0.874386</td>\n",
       "      <td>0.460770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lbfgs</th>\n",
       "      <td>0.874389</td>\n",
       "      <td>0.450857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>liblinear</th>\n",
       "      <td>0.874449</td>\n",
       "      <td>0.086412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sag</th>\n",
       "      <td>0.874352</td>\n",
       "      <td>0.220132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>saga</th>\n",
       "      <td>0.874386</td>\n",
       "      <td>0.321405</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           precision score  fit time\n",
       "newton-cg         0.874386  0.460770\n",
       "lbfgs             0.874389  0.450857\n",
       "liblinear         0.874449  0.086412\n",
       "sag               0.874352  0.220132\n",
       "saga              0.874386  0.321405"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# List solver types to loop over\n",
    "solvers = ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']\n",
    "\n",
    "# Initiate scores and fit times lists to store for each model\n",
    "scores = []\n",
    "fit_times = []\n",
    "\n",
    "# Loop over solvers\n",
    "for solver in solvers:\n",
    "    \n",
    "    # Cross validate each model\n",
    "    cv_log_s = cross_validate(\n",
    "        LogisticRegression(solver=solver),\n",
    "        X_scaled, y,\n",
    "        cv = 5,\n",
    "        scoring = ['precision']\n",
    "    )\n",
    "\n",
    "    # Append mean score and mean fit time to lists\n",
    "    scores.append(cv_log_s['test_precision'].mean())\n",
    "    fit_times.append(cv_log_s['fit_time'].mean())\n",
    "    \n",
    "# Create dataframe with each model's performance\n",
    "solvers_performance = pd.DataFrame({\"precision score\":scores, \"fit time\": fit_times}, index = solvers)\n",
    "solvers_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR ANSWER\n",
    "fastest_solver = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "delete"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'liblinear'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fastest_solver = solvers_performance['fit time'].idxmin()\n",
    "fastest_solver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>‚ÑπÔ∏è Click here for our interpretation</summary>\n",
    "\n",
    "All solvers should produce similar precision scores because our cost-function is \"easy\" enough to have a global minimum which is found by all 5 solvers. For very complex cost-functions such as in Deep Learning, different solvers may stopping at different values of the loss function.\n",
    "\n",
    "**The wine dataset**\n",
    "    \n",
    "If you check feature importance with sklearn's <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.inspection.permutation_importance.html\">permutation_importance</a> on the current dataset, you'll see many features result in almost 0 importance. Liblinear solver successively moves only along *one* direction at a time, regularizing the others with L1 regularization (a.k.a, setting their beta to 0), which might provide a good fit for a dataset where many features are not that important in predicting the target.\n",
    "\n",
    "‚ùóÔ∏èThere is a cost to searching for the best solver. Sticking with the default (`lbfgs`) may save the most time overall, sklearn provides you this grid for an idea of which solver to choose to start off with: \n",
    "\n",
    "<img src=\"https://wagon-public-datasets.s3.amazonaws.com/05-Machine-Learning/04-Under-the-Hood/solvers-chart.png\" width=700>\n",
    "\n",
    "\n",
    "\n",
    "</details> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  üß™ Test your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform darwin -- Python 3.10.6, pytest-7.1.3, pluggy-1.0.0 -- /Users/olivergiles/.pyenv/versions/3.10.6/envs/lewagon/bin/python3\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /Users/olivergiles/code/lewagon_dev/data-solutions/05-ML/04-Under-the-hood/02-Solvers/tests\n",
      "plugins: asyncio-0.19.0, anyio-3.6.2\n",
      "asyncio: mode=strict\n",
      "\u001b[1mcollecting ... \u001b[0mcollected 1 item\n",
      "\n",
      "test_solvers.py::TestSolvers::test_fastest_solver \u001b[32mPASSED\u001b[0m\u001b[32m                 [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m============================== \u001b[32m\u001b[1m1 passed\u001b[0m\u001b[32m in 0.02s\u001b[0m\u001b[32m ===============================\u001b[0m\n",
      "\n",
      "\n",
      "üíØ You can commit your code:\n",
      "\n",
      "\u001b[1;32mgit\u001b[39m add tests/solvers.pickle\n",
      "\n",
      "\u001b[32mgit\u001b[39m commit -m \u001b[33m'Completed solvers step'\u001b[39m\n",
      "\n",
      "\u001b[32mgit\u001b[39m push origin master\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from nbresult import ChallengeResult\n",
    "\n",
    "result = ChallengeResult(\n",
    "    'solvers',\n",
    "    fastest_solver=fastest_solver\n",
    ")\n",
    "result.write()\n",
    "print(result.check())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression models can also be optimized via Stochastic Gradient Descent.\n",
    "\n",
    "‚ùì Evaluate a Logistic Regression model optimized via **Stochastic Gradient Descent**. How do its precision score and training time compare to the performance of the models trained in section 2?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<details>\n",
    "<summary>üí° Hint</summary>\n",
    "\n",
    "- If you are stuck, look at the [SGDClassifier doc](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html)!\n",
    "\n",
    "</details>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "sgd_model = SGDClassifier(loss=\"log_loss\")\n",
    "\n",
    "cv_sgd = cross_validate(\n",
    "    sgd_model,\n",
    "    X_scaled, y,\n",
    "    cv = 5,\n",
    "    scoring = 'precision'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "delete"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8785496907910229"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Precision Score\n",
    "cv_sgd['test_score'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "delete"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.076513671875"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training time\n",
    "cv_sgd['fit_time'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚òùÔ∏è The SGD model should have one of the shortest times (maybe even shorter than `liblinear`), for similar performance. This is a direct effect of performing each epoch of the Gradient Descent on a single row as opposed to loading 100k rows into memory at a time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì Use the best model (balanced with short fit time and high precision) to predict the binary quality (0 or 1) of the following wine. Store your:\n",
    "- `predicted_class`\n",
    "- `predicted_proba_of_class` (i.e if your model predicted a class of 1 what is the probability it believes 1 to be the class should be between 0 and 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.54</td>\n",
       "      <td>13.5</td>\n",
       "      <td>12.35</td>\n",
       "      <td>8.78</td>\n",
       "      <td>14.72</td>\n",
       "      <td>9.06</td>\n",
       "      <td>9.67</td>\n",
       "      <td>10.15</td>\n",
       "      <td>11.17</td>\n",
       "      <td>12.17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0           9.54              13.5        12.35            8.78      14.72   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density  sulphates  alcohol  \n",
       "0                 9.06                  9.67    10.15      11.17    12.17  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_wine = pd.read_csv('https://wagon-public-datasets.s3.amazonaws.com/05-Machine-Learning/04-Under-the-Hood/solvers_new_wine.csv')\n",
    "new_wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train model with fastest training time\n",
    "best_model = SGDClassifier(loss=\"log_loss\").fit(X_scaled,y)\n",
    "\n",
    "# Scale new data using original scaler and restore the column names\n",
    "new_X = pd.DataFrame(scaler.transform(new_wine))\n",
    "new_X.columns = new_wine.columns\n",
    "\n",
    "# Predict!\n",
    "best_model.predict(new_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "delete"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_class = best_model.predict(new_X)[0]\n",
    "predicted_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "delete"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9669785275482368"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_proba_of_class = best_model.predict_proba(new_X)[0, predicted_class]\n",
    "predicted_proba_of_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üèÅ  Check your code and push your notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform darwin -- Python 3.8.12, pytest-6.2.5, py-1.11.0, pluggy-1.0.0 -- /Users/pavelliser/.pyenv/versions/lewagon/bin/python3\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /Users/pavelliser/Desktop/DataSciProgram/data-solutions/05-ML/04-Under-the-hood/02-Solvers\n",
      "plugins: anyio-3.4.0, dash-2.0.0\n",
      "\u001b[1mcollecting ... \u001b[0mcollected 2 items\n",
      "\n",
      "tests/test_new_data_prediction.py::TestNewDataPrediction::test_predicted_class \u001b[32mPASSED\u001b[0m\u001b[32m [ 50%]\u001b[0m\n",
      "tests/test_new_data_prediction.py::TestNewDataPrediction::test_predicted_proba \u001b[32mPASSED\u001b[0m\u001b[32m [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m============================== \u001b[32m\u001b[1m2 passed\u001b[0m\u001b[32m in 0.10s\u001b[0m\u001b[32m ===============================\u001b[0m\n",
      "\n",
      "\n",
      "üíØ You can commit your code:\n",
      "\n",
      "\u001b[1;32mgit\u001b[39m add tests/new_data_prediction.pickle\n",
      "\n",
      "\u001b[32mgit\u001b[39m commit -m \u001b[33m'Completed new_data_prediction step'\u001b[39m\n",
      "\n",
      "\u001b[32mgit\u001b[39m push origin master\n"
     ]
    }
   ],
   "source": [
    "from nbresult import ChallengeResult\n",
    "\n",
    "result = ChallengeResult(\n",
    "    'new_data_prediction',\n",
    "    predicted_class=predicted_class,\n",
    "    predicted_proba_of_class=predicted_proba_of_class\n",
    ")\n",
    "result.write()\n",
    "print(result.check())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
